---
AWSTemplateFormatVersion: '2010-09-09'
Description: 'Amazon EKS - Node Group definition with support for Cluster Autoscaler and Proxy'

Parameters:
  K8sVersion:
    Type: String
    Default: '11'
    Description: Choose Kubernetes version 1.X
    AllowedValues:
    - '11'
    - '12'
    - '13'

  VpcId:
    Type: AWS::EC2::VPC::Id
    Description: Define VPC ID where worker nodes will be deployed
  
  ClusterControlPlaneSecurityGroup:
    Type: AWS::EC2::SecurityGroup::Id
    Description: Choose security group uses by EKS control plane

  PrivateSubnets:
    Type: String
    Description: Define private subnets on VPC for proxy server, multiple Subnet Ids separated by comma subnet-123,subnet-456

  ClusterCidr:
    Type: String
    Description: Define VPC CIDRs, multiple CIDRs are separated by a comma eg. 172.16.0.0/16,10.0.0.0/16

  ProxyUrl:
    Type: String
    Description: Define proxy server NLB URL

  ProxyPort:
    Type: Number
    Default: 3128
    Description: Define the port number on proxy server for proxy server process to open and listen

  ProxySecurityGroup:
    Type: AWS::EC2::SecurityGroup::Id
    Description: Define proxy's security group, this is required to allow SSH access to worker nodes from proxy server

  KeyName:
    Description: SSH key name to enable SSH access to proxy server and worker nodes
    Type: AWS::EC2::KeyPair::KeyName
    Default: rmaulan-testbed

  NodeGPUSupport:
    Type: String
    Description: SSH key name to enable SSH access to proxy server and worker nodes
    Default: nogpu
    AllowedValues:
    - nogpu
    - gpu

  NodeInstanceType:
    Description: Define EC2 instance type for EKS worker node
    Type: String
    Default: t2.medium
    AllowedValues:
    - t2.small
    - t2.medium
    - t2.large
    - t2.xlarge
    - t2.2xlarge
    - m3.medium
    - m3.large
    - m3.xlarge
    - m3.2xlarge
    - m4.large
    - m4.xlarge
    - m4.2xlarge
    - m4.4xlarge
    - m4.10xlarge
    - m5.large
    - m5.xlarge
    - m5.2xlarge
    - m5.4xlarge
    - m5.12xlarge
    - m5.24xlarge
    - c4.large
    - c4.xlarge
    - c4.2xlarge
    - c4.4xlarge
    - c4.8xlarge
    - c5.large
    - c5.xlarge
    - c5.2xlarge
    - c5.4xlarge
    - c5.9xlarge
    - c5.18xlarge
    - i3.large
    - i3.xlarge
    - i3.2xlarge
    - i3.4xlarge
    - i3.8xlarge
    - i3.16xlarge
    - r3.xlarge
    - r3.2xlarge
    - r3.4xlarge
    - r3.8xlarge
    - r4.large
    - r4.xlarge
    - r4.2xlarge
    - r4.4xlarge
    - r4.8xlarge
    - r4.16xlarge
    - x1.16xlarge
    - x1.32xlarge
    - p2.xlarge
    - p2.8xlarge
    - p2.16xlarge
    - p3.2xlarge
    - p3.8xlarge
    - p3.16xlarge
    ConstraintDescription: Must be a valid EC2 instance type

  NodeAutoScalingGroupMinSize:
    Type: Number
    Description: Minimum number of worker node in the cluster.
    Default: 1

  NodeAutoScalingGroupMaxSize:
    Type: Number
    Description: Maximum number of worker node in the cluster.
    Default: 100 

  NodeVolumeSize:
    Type: Number
    Description: Define the size of worker node storage
    Default: 20

  ClusterName:
    Description: Give the name of EKS cluster. If it is incorrect, nodes will not be able to join the cluster.
    Type: String

  BootstrapArguments:
    Description: Arguments to pass to the bootstrap script. See files/bootstrap.sh in https://github.com/awslabs/amazon-eks-ami
    Default: ""
    Type: String

Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: 'EKS Cluster Configurations'
        Parameters:
        - ClusterName
        - K8sVersion
        - ClusterControlPlaneSecurityGroup

      - Label:
          default: 'VPC Configurations'
        Parameters:
        - VpcId
        - PrivateSubnets
        - ClusterCidr

      - Label:
          default: 'Proxy Configurations'
        Parameters:
        - ProxyUrl
        - ProxyPort
        - ProxySecurityGroup

      - Label:
          default: 'Worker Node Configuration'
        Parameters:
        - NodeAutoScalingGroupMinSize
        - NodeAutoScalingGroupMaxSize
        - NodeInstanceType
        - NodeGPUSupport
        - NodeVolumeSize
        - KeyName
        - BootstrapArguments
      
      - Label:
          default: "EC2 Instance Accessibility"
        Parameters:
        - KeyName

Mappings:
{{ .AmiList }}

Resources:
  NodeInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Path: "/"
      Roles:
      - !Ref NodeInstanceRole

  NodeInstanceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - ec2.amazonaws.com
          Action:
          - sts:AssumeRole
      Path: "/"
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy
        - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy
        - arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly
      Policies:
      - PolicyName: cluster-autoscaler
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - 'autoscaling:DescribeAutoScalingGroups'
            - 'autoscaling:DescribeAutoScalingInstances'
            - 'autoscaling:DescribeLaunchConfigurations'
            - 'autoscaling:DescribeTags'
            - 'autoscaling:SetDesiredCapacity'
            - 'autoscaling:TerminateInstanceInAutoScalingGroup'
            Resource: '*'

  NodeSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for all nodes in the cluster
      VpcId: !Ref VpcId
      Tags:
      - Key: !Sub "kubernetes.io/cluster/${ClusterName}"
        Value: 'owned'
        
  NodeSecurityGroupIngress:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      Description: Allow node to communicate with each other
      GroupId: !Ref NodeSecurityGroup
      SourceSecurityGroupId: !Ref NodeSecurityGroup
      IpProtocol: '-1'
      FromPort: 0
      ToPort: 65535
  
  NodeSecurityGroupFromBastionIngress:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      Description: Allow Bastion to SSH to worker node
      GroupId: !Ref NodeSecurityGroup
      SourceSecurityGroupId: !Ref ProxySecurityGroup
      IpProtocol: tcp
      FromPort: 22
      ToPort: 22

  NodeSecurityGroupFromControlPlaneIngress:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      Description: Allow worker Kubelets and pods to receive communication from the cluster control plane
      GroupId: !Ref NodeSecurityGroup
      SourceSecurityGroupId: !Ref ClusterControlPlaneSecurityGroup
      IpProtocol: tcp
      FromPort: 1025
      ToPort: 65535

  ControlPlaneEgressToNodeSecurityGroup:
    Type: AWS::EC2::SecurityGroupEgress
    Properties:
      Description: Allow the cluster control plane to communicate with worker Kubelet and pods
      GroupId: !Ref ClusterControlPlaneSecurityGroup
      DestinationSecurityGroupId: !Ref NodeSecurityGroup
      IpProtocol: tcp
      FromPort: 1025
      ToPort: 65535

  NodeSecurityGroupFromControlPlaneOn443Ingress:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      Description: Allow pods running extension API servers on port 443 to receive communication from cluster control plane
      GroupId: !Ref NodeSecurityGroup
      SourceSecurityGroupId: !Ref ClusterControlPlaneSecurityGroup
      IpProtocol: tcp
      FromPort: 443
      ToPort: 443

  ControlPlaneEgressToNodeSecurityGroupOn443:
    Type: AWS::EC2::SecurityGroupEgress
    Properties:
      Description: Allow the cluster control plane to communicate with pods running extension API servers on port 443
      GroupId: !Ref ClusterControlPlaneSecurityGroup
      DestinationSecurityGroupId: !Ref NodeSecurityGroup
      IpProtocol: tcp
      FromPort: 443
      ToPort: 443

  ClusterControlPlaneSecurityGroupIngress:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      Description: Allow pods to communicate with the cluster API Server
      GroupId: !Ref ClusterControlPlaneSecurityGroup
      SourceSecurityGroupId: !Ref NodeSecurityGroup
      IpProtocol: tcp
      ToPort: 443
      FromPort: 443

  NodeGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    Properties:
      DesiredCapacity: !Ref NodeAutoScalingGroupMinSize
      LaunchConfigurationName: !Ref NodeLaunchConfig
      MinSize: !Ref NodeAutoScalingGroupMinSize
      MaxSize: !Ref NodeAutoScalingGroupMaxSize
      VPCZoneIdentifier:
        Fn::Split:
        - ','
        - !Ref PrivateSubnets
      Tags:
      - Key: Name
        Value: !Sub "${ClusterName}-worker-node"
        PropagateAtLaunch: true
      - Key: !Sub 'kubernetes.io/cluster/${ClusterName}'
        Value: 'true'
        PropagateAtLaunch: true
      - Key: k8s.io/cluster-autoscaler/enabled
        Value: 'true'
        PropagateAtLaunch: true
    UpdatePolicy:
      AutoScalingRollingUpdate:
        MinInstancesInService: 1
        MaxBatchSize: 5

  NodeLaunchConfig:
    Type: AWS::AutoScaling::LaunchConfiguration
    Properties:
      AssociatePublicIpAddress: false
      IamInstanceProfile: !Ref NodeInstanceProfile
      ImageId: 
        Fn::FindInMap:
        - !Ref K8sVersion
        - !Ref AWS::Region
        - !Ref NodeGPUSupport
      InstanceType: !Ref NodeInstanceType
      KeyName: !Ref KeyName
      SecurityGroups:
      - !Ref NodeSecurityGroup
      BlockDeviceMappings:
        - DeviceName: /dev/xvda
          Ebs:
            VolumeSize: !Ref NodeVolumeSize
            VolumeType: gp2
            DeleteOnTermination: true
      UserData:
        Fn::Base64:
          !Sub |
            #!/bin/bash
            set -o xtrace

            # Create the docker systemd directory
            mkdir -p /etc/systemd/system/docker.service.d

            # Configure yum to use the proxy
            cat << EOF >> /etc/yum.conf
            proxy=http://${ProxyUrl}:${ProxyPort}
            EOF

            # Set the proxy for future processes, and use as an include file
            cat << EOF >> /etc/environment
            http_proxy=http://${ProxyUrl}:${ProxyPort}
            https_proxy=http://${ProxyUrl}:${ProxyPort}
            HTTP_PROXY=http://${ProxyUrl}:${ProxyPort}
            HTTPS_PROXY=http://${ProxyUrl}:${ProxyPort}
            no_proxy=${ClusterCidr},localhost,127.0.0.1,169.254.169.254,.internal
            NO_PROXY=${ClusterCidr},localhost,127.0.0.1,169.254.169.254,.internal
            EOF

            # Configure docker with the proxy
            cat << EOF >> /etc/systemd/system/docker.service.d/proxy.conf
            [Service]
            EnvironmentFile=/etc/environment
            EOF

            # Configure the kubelet with the proxy
            cat << EOF >> /etc/systemd/system/kubelet.service.d/proxy.conf
            [Service]
            EnvironmentFile=/etc/environment
            EOF
            
            # Pick up the docker systemd directory
            systemctl daemon-reload

            # Restart docker so it fetch the proxy parameters
            systemctl stop docker
            systemctl start docker

            # Set the proxy variables before running the bootstrap.sh script
            set -a
            source /etc/environment

            /etc/eks/bootstrap.sh ${ClusterName} ${BootstrapArguments}

Outputs:
  NodeInstanceRole:
    Description: The node instance role
    Value: !GetAtt NodeInstanceRole.Arn